{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import pyedflib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import savemat, loadmat\n",
    "data_dir = '../../training dataset/'\n",
    "subject_id = 1\n",
    "raw_data_file = 'task_Sub' + str(subject_id)\n",
    "raw_data = loadmat(data_dir + raw_data_file)\n",
    "# file_name = 'sub6-2' # filename for saving model weight\n",
    "data = raw_data['data']\n",
    "# data = np.rollaxis(data, 2, 1) # use this line depending on the expected data shape\n",
    "label = raw_data['label'] - 2\n",
    "# label = np.rollaxis(label, 1, 0)\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# data, x_test, label, y_test = train_test_split(x_subject, y_subject, test_size=0.33, random_state=42)\n",
    "data_reshaped = np.empty([data.shape[0]*data.shape[2], data.shape[1]])\n",
    "label_reshaped = np.empty([data.shape[0]*data.shape[2]])\n",
    "for trial in range (data.shape[0]):\n",
    "    for data_point in range (data.shape[2]):\n",
    "        reshaped_row = trial * data.shape[2] + data_point\n",
    "        data_reshaped[reshaped_row, :] = data[trial, :, data_point]\n",
    "        label_reshaped[reshaped_row] = label[0,trial]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! /usr/bin/python3\n",
    "\n",
    "########################################################\n",
    "# EEG data preprocess for 1D/2D/3D\n",
    "########################################################\n",
    "\n",
    "\n",
    "np.random.seed(0)\n",
    "def get_args():\n",
    "\tparser = argparse.ArgumentParser()\n",
    "\t\n",
    "\thpstr = \"set dataset directory\"\n",
    "\tinput_dir = \"../raw_data/\" # original repository: \"/home/dadafly/datasets/EEG_motor_imagery/\"\n",
    "\n",
    "\tparser.add_argument('-d', '--directory', default=input_dir, nargs='*', type=str, help=hpstr)\n",
    "\n",
    "\n",
    "\thpstr = \"set window size\"\n",
    "\tparser.add_argument('-w', '--window', default=10, nargs='*', type=int, help=hpstr)\n",
    "\n",
    "\thpstr = \"set whether parallel\"\n",
    "\tparser.add_argument('--parallel', default = False, action='store_true', help=hpstr) # add default\n",
    "\n",
    "\thpstr = \"set whether convert to 2D matrix\"\n",
    "\tparser.add_argument('--convert', default = True, action='store_true', help=hpstr) # add default\n",
    "\n",
    "\thpstr = \"set whether segment data\"\n",
    "\tparser.add_argument('--segment', default = True, action='store_true', help=hpstr) # add default\n",
    "\n",
    "\thpstr = \"set begin person\"\n",
    "\tparser.add_argument('-b', '--begin', default=1, nargs='?', type=int, help=hpstr)\n",
    "\n",
    "\thpstr = \"set end person\"\n",
    "\tparser.add_argument('-e', '--end', default=108, nargs='?', type=int, help=hpstr)\n",
    "\n",
    "\thpstr = \"set output directory\"\n",
    "\tparser.add_argument('-o', '--output_dir', default=input_dir, nargs='*', help=hpstr)\n",
    "\n",
    "\thpstr = \"set whether store data\"\n",
    "\tparser.add_argument('--set_store', default = True, action='store_true', help=hpstr) # add default\n",
    "\n",
    "\targs = parser.parse_args()\n",
    "\treturn(args)\n",
    "\t\t   \n",
    "def print_top(subject_id, window_size, parallel, convert, segment, output_dir, set_store):\n",
    "\t# \t\t   \\n#### Author: Dalin Zhang\tUNSW, Sydney\temail: zhangdalin90@gmail.com #####\t\\\n",
    "\tprint(\"######################## Six-class MI EEG data preprocess ########################\t\\\n",
    "\t   \t   \\n# subject ID:\t%s \\\n",
    "\t\t   \\n# window size:\t\t%d \t\\\n",
    "\t\t   \\n# parallel:\t%s \t\\\n",
    "\t\t   \\n# convert:\t\t%s \t\\\n",
    "\t\t   \\n# segment:\t\t%s \t\\\n",
    "\t\t   \\n# output directory:\t%s\t\\\n",
    "\t\t   \\n# set store:\t\t%s \t\\\n",
    "\t\t   \\n##############################################################################\"% \\\n",
    "\t\t\t(subject_id,\t\\\n",
    "\t\t\twindow_size,\t\\\n",
    "\t\t\tparallel,       \\\n",
    "\t\t\tconvert,\t\t\\\n",
    "\t\t\tsegment,\t\t\\\n",
    "\t\t\toutput_dir,\t\t\\\n",
    "\t\t\tset_store))\n",
    "\treturn None\n",
    "\n",
    "\n",
    "def read_data(file_name):\n",
    "\tf = pyedflib.EdfReader(file_name)\n",
    "\tn = f.signals_in_file\n",
    "\tsignal_labels = f.getSignalLabels()\n",
    "\tsigbufs = np.zeros((n, f.getNSamples()[0]))\n",
    "\tfor i in np.arange(n):\n",
    "\t    sigbufs[i, :] = f.readSignal(i)\n",
    "\tsigbuf_transpose = np.transpose(sigbufs)\n",
    "\tsignal = np.asarray(sigbuf_transpose)\n",
    "\tsignal_labels = np.asarray(signal_labels)\n",
    "\tf._close()\n",
    "\tdel f\n",
    "\treturn signal, signal_labels\n",
    "\n",
    "# def data_1Dto2D(data, Y=10, X=11): # comment out by TZ\n",
    "# \tdata_2D = np.zeros([Y, X])\n",
    "# \tdata_2D[0] = ( \t   \t 0, \t   0,  \t   \t 0, \t   0, data[21], data[22], data[23], \t   0,  \t     0, \t   0, \t \t 0) \n",
    "# \tdata_2D[1] = (\t  \t 0, \t   0,  \t   \t 0, data[24], data[25], data[26], data[27], data[28], \t   \t 0,   \t   0, \t \t 0) \n",
    "# \tdata_2D[2] = (\t  \t 0, data[29], data[30], data[31], data[32], data[33], data[34], data[35], data[36], data[37], \t \t 0) \n",
    "# \tdata_2D[3] = (\t  \t 0, data[38],  data[0],  data[1],  data[2],  data[3],  data[4],  data[5],  data[6], data[39], \t\t 0) \n",
    "# \tdata_2D[4] = (data[42], data[40],  data[7],  data[8],  data[9], data[10], data[11], data[12], data[13], data[41], data[43]) \n",
    "# \tdata_2D[5] = (\t  \t 0, data[44], data[14], data[15], data[16], data[17], data[18], data[19], data[20], data[45], \t\t 0) \n",
    "# \tdata_2D[6] = (\t  \t 0, data[46], data[47], data[48], data[49], data[50], data[51], data[52], data[53], data[54], \t\t 0) \n",
    "# \tdata_2D[7] = (\t  \t 0, \t   0, \t \t 0, data[55], data[56], data[57], data[58], data[59], \t   \t 0, \t   0, \t\t 0) \n",
    "# \tdata_2D[8] = (\t  \t 0, \t   0, \t \t 0, \t   0, data[60], data[61], data[62], \t   0, \t   \t 0, \t   0, \t\t 0) \n",
    "# \tdata_2D[9] = (\t  \t 0, \t   0, \t \t 0, \t   0, \t     0, data[63], \t\t 0, \t   0, \t   \t 0, \t   0, \t\t 0) \n",
    "# \treturn data_2D\n",
    "\n",
    "def data_1Dto2D(data, Y=10, X=11): # add by TZ for huang's proj\n",
    "\tdata_2D = np.zeros([Y, X])\n",
    "\tdata_2D[0] = ( \t   \t 0, \t   0,  \t   \t 0, \t   0, \t     0, \t   0, \t     0, \t   0,  \t     0, \t   0, \t \t 0) \n",
    "\tdata_2D[1] = (\t  \t 0, \t   0,  \t   \t 0, \t   0, \t     0, \t   0, \t     0, \t   0, \t   \t 0,   \t   0, \t \t 0) \n",
    "\tdata_2D[2] = (\t  \t 0, \t   0,  data[0],  data[1],  data[2],  data[3],  data[4],  data[5],  data[6],   \t   0, \t \t 0) \n",
    "\tdata_2D[3] = (\t  \t 0,   \t   0,  data[7],  data[8], data[9], data[10], data[11], data[12], data[13],   \t   0, \t\t 0) \n",
    "\tdata_2D[4] = (   \t 0,   \t   0, data[14], data[15], data[16], data[17], data[18], data[19], data[20],    \t   0,   \t 0) \n",
    "\tdata_2D[5] = (\t  \t 0,   \t   0,        0, data[21], data[22], data[23], data[24], data[25],        0,   \t   0, \t\t 0) \n",
    "\tdata_2D[6] = (\t  \t 0,   \t   0,        0, data[26], data[27], data[28], data[29], data[30],    \t 0,   \t   0, \t\t 0) \n",
    "\tdata_2D[7] = (\t  \t 0, \t   0, \t \t 0,    \t   0,   \t 0,   \t   0,   \t 0,   \t   0, \t   \t 0, \t   0, \t\t 0) \n",
    "\tdata_2D[8] = (\t  \t 0, \t   0, \t \t 0, \t   0,        0,   \t   0,   \t 0, \t   0, \t   \t 0, \t   0, \t\t 0) \n",
    "\tdata_2D[9] = (\t  \t 0, \t   0, \t \t 0, \t   0, \t     0,   \t   0, \t\t 0, \t   0, \t   \t 0, \t   0, \t\t 0) \n",
    "\treturn data_2D\n",
    "\n",
    "def norm_dataset(dataset_1D):\n",
    "\tnorm_dataset_1D = np.zeros([dataset_1D.shape[0], 31])\n",
    "\tfor i in range(dataset_1D.shape[0]):\n",
    "\t\tnorm_dataset_1D[i] = feature_normalize(dataset_1D[i])\n",
    "\treturn norm_dataset_1D\n",
    "\n",
    "def feature_normalize(data):\n",
    "\tmean = data[data.nonzero()].mean()\n",
    "\tsigma = data[data.nonzero()].std()\n",
    "\tdata_normalized = data\n",
    "\tdata_normalized[data_normalized.nonzero()] = (data_normalized[data_normalized.nonzero()] - mean)/sigma\n",
    "\treturn data_normalized\n",
    "\n",
    "def dataset_1Dto2D(dataset_1D):\n",
    "\tdataset_2D = np.zeros([dataset_1D.shape[0], 10, 11])\n",
    "\tfor i in range(dataset_1D.shape[0]):\n",
    "\t\tdataset_2D[i] = data_1Dto2D(dataset_1D[i])\n",
    "\treturn dataset_2D\n",
    "\n",
    "def norm_dataset_1Dto2D(dataset_1D):\n",
    "\tnorm_dataset_2D = np.zeros([dataset_1D.shape[0], 10, 11])\n",
    "\tfor i in range(dataset_1D.shape[0]):\n",
    "\t\tnorm_dataset_2D[i] = feature_normalize(data_1Dto2D(dataset_1D[i]))\n",
    "\treturn norm_dataset_2D\n",
    "\n",
    "def windows(data, size):\n",
    "\tstart = 0\n",
    "\twhile ((start+size) < data.shape[0]):\n",
    "\t\tyield int(start), int(start + size)\n",
    "\t\tstart += (size/2)\n",
    "\n",
    "\n",
    "def segment_signal_without_transition(data, label, window_size):\n",
    "    # start_time = time.time()  # Record the start time\n",
    "    # total_steps = len(data) - window_size + 1  # Total number of possible windows\n",
    "    # processed_steps = 0  # To track how many windows are processed\n",
    "\n",
    "    for (start, end) in windows(data, window_size):\n",
    "\n",
    "        # processed_steps += 1\n",
    "        # # Progress and remaining time estimation\n",
    "        # if processed_steps % 1000 == 0:  # Print progress every 1000 steps\n",
    "        #     elapsed_time = time.time() - start_time\n",
    "        #     progress = processed_steps / total_steps\n",
    "        #     remaining_time = elapsed_time / progress - elapsed_time\n",
    "        #     print(f\"Progress: {progress:.2%}, \"\n",
    "        #           f\"Elapsed Time: {elapsed_time:.2f}s, \"\n",
    "        #           f\"Estimated Remaining Time: {remaining_time:.2f}s\")\n",
    "\n",
    "        # Original functionality\n",
    "        if ((len(data[start:end]) == window_size) and (len(set(label[start:end])) == 1)):\n",
    "            if start == 0:\n",
    "                segments = data[start:end]\n",
    "                labels = np.array(list(set(label[start:end])))\n",
    "            else:\n",
    "                segments = np.vstack([segments, data[start:end]])\n",
    "                labels = np.append(labels, np.array(list(set(label[start:end]))))\n",
    "    return segments, labels\n",
    "\n",
    "\n",
    "\n",
    "def apply_mixup(all_data, all_label, parallel, convert, segment, window_size):\n",
    "\n",
    "\t# initial empty label arrays\n",
    "\tlabel_inter\t= np.empty([0])\n",
    "\t# initial empty data arrays\n",
    "\tif (parallel == True):\n",
    "\t\tdata_inter_cnn\t= np.empty([0, window_size, 10, 11])\n",
    "\t\tdata_inter_rnn\t= np.empty([0, window_size, 64]) # 64-> 32??\n",
    "\telif ((convert == False) and (segment == False)):\n",
    "\t\tdata_inter\t= np.empty([0, 64]) # 64-> 32??\n",
    "\telif ((convert == False) and (segment == True)): \n",
    "\t\tdata_inter\t= np.empty([0, window_size, 64]) # 64-> 32??\n",
    "\telif ((convert == True) and (segment == False)): \n",
    "\t\tdata_inter\t= np.empty([0, 10, 11])\n",
    "\telif ((convert == True) and (segment == True)): # cascade\n",
    "\t\tdata_inter\t= np.empty([0, window_size, 10, 11])\n",
    "\n",
    "\tall_data = norm_dataset(all_data)\n",
    "\n",
    "\tstep_size = 2401*10\n",
    "\tfor start in range (0, all_data.shape[0], step_size):\n",
    "\t\tend = start + step_size\n",
    "\t\tdata = all_data[start:end, :]\n",
    "\t\tlabel = all_label[start:end]\n",
    "\t\tprint(\"Now processing until: \"+str(end))\n",
    "\t\tif (parallel == True):\n",
    "\t\t\t# segment data\n",
    "\t\t\tdata, label\t= segment_signal_without_transition(data, label, window_size)\n",
    "\t\t\t# cnn data process\n",
    "\t\t\tdata_cnn\t= dataset_1Dto2D(data)\n",
    "\t\t\tdata_cnn\t= data_cnn.reshape(int(data_cnn.shape[0]/window_size), window_size, 10, 11)\n",
    "\t\t\t# rnn data process\n",
    "\t\t\tdata_rnn\t= data_cnn.reshape(int(data.shape[0]/window_size), window_size, 64)\n",
    "\t\telif ((convert == False) and (segment == False)):\n",
    "\t\t\tpass\n",
    "\t\telif ((convert == False) and (segment == True)):\n",
    "\t\t\t# segment data with sliding window \n",
    "\t\t\tdata, label\t= segment_signal_without_transition(data, label, window_size)\n",
    "\t\t\tdata\t\t= data.reshape(int(data.shape[0]/window_size), window_size, 64)\n",
    "\t\telif ((convert == True) and (segment == False)): \n",
    "\t\t\t# convert 1D data to 2D\n",
    "\t\t\tdata\t\t= dataset_1Dto2D(data)\n",
    "\t\telif ((convert == True) and (segment == True)): # cascade\n",
    "\t\t\t# convert 1D data to 2D\n",
    "\t\t\tdata\t\t= dataset_1Dto2D(data)\n",
    "\t\t\t# segment data with sliding window \n",
    "\t\t\tdata, label\t= segment_signal_without_transition(data, label, window_size)\n",
    "\t\t\tdata\t\t= data.reshape(int(data.shape[0]/window_size), window_size, 10, 11)\n",
    "\n",
    "\t\t# append new data and label\n",
    "\t\tif (parallel == True):\n",
    "\t\t\tdata_inter_cnn\t= np.vstack([data_inter_cnn, data_cnn])\n",
    "\t\t\tdata_inter_rnn\t= np.vstack([data_inter_rnn, data_rnn])\n",
    "\t\t\tlabel_inter\t= np.append(label_inter, label)\n",
    "\t\telse:\n",
    "\t\t\tdata_inter\t= np.vstack([data_inter, data])\n",
    "\t\t\tlabel_inter\t= np.append(label_inter, label)\n",
    "\n",
    "\n",
    "\t# shuffle data\n",
    "\tindex = np.array(range(0, len(label_inter)))\n",
    "\tnp.random.shuffle(index)\n",
    "\tif (parallel==True):\n",
    "\t\tshuffled_data_cnn\t= data_inter_cnn[index]\n",
    "\t\tshuffled_data_rnn\t= data_inter_rnn[index]\n",
    "\t\tshuffled_label \t= label_inter[index]\n",
    "\telse:\n",
    "\t\tshuffled_data\t= data_inter[index]\n",
    "\t\tshuffled_label \t= label_inter[index]\n",
    "\treturn shuffled_data, shuffled_label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######################## Six-class MI EEG data preprocess ########################\t\t   \t   \n",
      "# subject ID:\t1 \t\t   \n",
      "# window size:\t\t10 \t\t\t   \n",
      "# parallel:\tFalse \t\t\t   \n",
      "# convert:\t\tTrue \t\t\t   \n",
      "# segment:\t\tTrue \t\t\t   \n",
      "# output directory:\t../../training dataset for CRNN/\t\t\t   \n",
      "# set store:\t\tTrue \t\t\t   \n",
      "##############################################################################\n",
      "Now processing until: 24010\n",
      "Now processing until: 48020\n",
      "Now processing until: 72030\n",
      "Now processing until: 96040\n",
      "Now processing until: 120050\n",
      "Now processing until: 144060\n",
      "Now processing until: 168070\n",
      "Now processing until: 192080\n",
      "Now processing until: 216090\n",
      "Now processing until: 240100\n",
      "Now processing until: 264110\n",
      "Now processing until: 288120\n",
      "Now processing until: 312130\n",
      "Now processing until: 336140\n",
      "Now processing until: 360150\n",
      "Now processing until: 384160\n",
      "Now processing until: 408170\n",
      "Now processing until: 432180\n",
      "Now processing until: 456190\n",
      "Now processing until: 480200\n",
      "Now processing until: 504210\n",
      "Now processing until: 528220\n",
      "Now processing until: 552230\n",
      "Now processing until: 576240\n",
      "Now processing until: 600250\n",
      "Now processing until: 624260\n",
      "Now processing until: 648270\n"
     ]
    }
   ],
   "source": [
    "# input directory:      ../raw_data/               \n",
    "# window size:          10                         \n",
    "# parallel:     False                      \n",
    "# convert:              True                       \n",
    "# segment:              True                       \n",
    "# begin subject:        1                          \n",
    "# end subject:          108                        \n",
    "# output directory:     ../raw_data/                       \n",
    "# set store:            True  \n",
    "\n",
    "# dataset_dir\t\t=\t\"../../raw_data_CRNN/\" # get_args().directory\n",
    "window_size\t\t=\t10 # get_args().window\n",
    "parallel\t\t=\tFalse # get_args().parallel\n",
    "convert\t\t\t=\tTrue # get_args().convert\n",
    "segment\t\t\t=\tTrue # get_args().segment\n",
    "begin_subject\t=\t1 # get_args().begin\n",
    "end_subject\t\t=\t108 # get_args().end\n",
    "output_dir\t\t=\t\"../../training dataset for CRNN/\" # get_args().output_dir\n",
    "set_store\t\t=\tTrue # get_args().set_store\n",
    "print_top(subject_id, window_size, parallel, convert, segment, output_dir, set_store)\n",
    "# print('stop here')\n",
    "# exit()\n",
    "shuffled_data, shuffled_label = apply_mixup(data_reshaped, label_reshaped, parallel, convert, segment, window_size)\n",
    "# 17m 30s on macbook\n",
    "# 21m 5s on WIN desktop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WE ARE HERE!!!\n"
     ]
    }
   ],
   "source": [
    "if (set_store == True):\n",
    "\tif (parallel == True):\n",
    "\t\toutput_data_cnn = output_dir+\"parallel_cnn_rnn/raw_data/\"+str(begin_subject)+\"_\"+str(end_subject)+\"_shuffle_cnn_dataset.pkl\"\n",
    "\t\toutput_data_rnn = output_dir+\"parallel_cnn_rnn/raw_data/\"+str(begin_subject)+\"_\"+str(end_subject)+\"_shuffle_rnn_dataset.pkl\"\n",
    "\t\toutput_label= output_dir+\"parallel_cnn_rnn/raw_data/\"+str(begin_subject)+\"_\"+str(end_subject)+\"_shuffle_labels.pkl\"\n",
    "\telif ((convert == False) and (segment == False)): # default to here\n",
    "\t\toutput_data = output_dir+\"1D_CNN/raw_data/\"+str(begin_subject)+\"_\"+str(end_subject)+\"_shuffle_dataset_1D.pkl\"\n",
    "\t\toutput_label= output_dir+\"1D_CNN/raw_data/\"+str(begin_subject)+\"_\"+str(end_subject)+\"_shuffle_labels_1D.pkl\"\n",
    "\telif ((convert == False) and (segment == True)): \n",
    "\t\toutput_data = output_dir+\"1D_CNN/raw_data/window_1D/\"+str(begin_subject)+\"_\"+str(end_subject)+\"_shuffle_dataset_1D_win_\"+str(window_size)+\".pkl\"\n",
    "\t\toutput_label= output_dir+\"1D_CNN/raw_data/window_1D/\"+str(begin_subject)+\"_\"+str(end_subject)+\"_shuffle_labels_1D_win_\"+str(window_size)+\".pkl\"\n",
    "\telif ((convert == True) and (segment == False)): \n",
    "\t\toutput_data = output_dir+\"2D_CNN/raw_data/\"+str(begin_subject)+\"_\"+str(end_subject)+\"_shuffle_dataset_2D.pkl\"\n",
    "\t\toutput_label= output_dir+\"2D_CNN/raw_data/\"+str(begin_subject)+\"_\"+str(end_subject)+\"_shuffle_labels_2D.pkl\"\n",
    "\telif ((convert == True) and (segment == True)): # cascade\n",
    "\t\tprint(\"FOR CASCADE!\")\n",
    "\t\toutput_data = output_dir+\"3D_CNN/raw_data/\"+str(begin_subject)+\"_\"+str(end_subject)+\"_shuffle_dataset_3D_win_\"+str(window_size)+\".pkl\"\n",
    "\t\toutput_label= output_dir+\"3D_CNN/raw_data/\"+str(begin_subject)+\"_\"+str(end_subject)+\"_shuffle_labels_3D_win_\"+str(window_size)+\".pkl\"\n",
    "\n",
    "\tos.makedirs(os.path.dirname(output_data), exist_ok=True) # add by TZ\n",
    "\n",
    "\tif (parallel ==True):\n",
    "\t\twith open(output_data_cnn, \"wb\") as fp:\n",
    "\t\t\tpickle.dump(shuffled_data_cnn, fp, protocol=4) \n",
    "\t\twith open(output_data_rnn, \"wb\") as fp:\n",
    "\t\t\tpickle.dump(shuffled_data_rnn, fp, protocol=4) \n",
    "\t\twith open(output_label, \"wb\") as fp:\n",
    "\t\t\tpickle.dump(shuffled_label, fp)\n",
    "\telse: # default to here\n",
    "\t\twith open(output_data, \"wb\") as fp:\n",
    "\t\t\tpickle.dump(shuffled_data, fp, protocol=4)\n",
    "\t\twith open(output_label, \"wb\") as fp:\n",
    "\t\t\tpickle.dump(shuffled_label, fp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
