{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import pyedflib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! /usr/bin/python3\n",
    "\n",
    "########################################################\n",
    "# EEG data preprocess for 1D/2D/3D\n",
    "########################################################\n",
    "\n",
    "\n",
    "np.random.seed(0)\n",
    "def get_args():\n",
    "\tparser = argparse.ArgumentParser()\n",
    "\t\n",
    "\thpstr = \"set dataset directory\"\n",
    "\tinput_dir = \"../raw_data/\" # original repository: \"/home/dadafly/datasets/EEG_motor_imagery/\"\n",
    "\n",
    "\tparser.add_argument('-d', '--directory', default=input_dir, nargs='*', type=str, help=hpstr)\n",
    "\n",
    "\n",
    "\thpstr = \"set window size\"\n",
    "\tparser.add_argument('-w', '--window', default=10, nargs='*', type=int, help=hpstr)\n",
    "\n",
    "\thpstr = \"set whether parallel\"\n",
    "\tparser.add_argument('--parallel', default = False, action='store_true', help=hpstr) # add default\n",
    "\n",
    "\thpstr = \"set whether convert to 2D matrix\"\n",
    "\tparser.add_argument('--convert', default = True, action='store_true', help=hpstr) # add default\n",
    "\n",
    "\thpstr = \"set whether segment data\"\n",
    "\tparser.add_argument('--segment', default = True, action='store_true', help=hpstr) # add default\n",
    "\n",
    "\thpstr = \"set begin person\"\n",
    "\tparser.add_argument('-b', '--begin', default=1, nargs='?', type=int, help=hpstr)\n",
    "\n",
    "\thpstr = \"set end person\"\n",
    "\tparser.add_argument('-e', '--end', default=108, nargs='?', type=int, help=hpstr)\n",
    "\n",
    "\thpstr = \"set output directory\"\n",
    "\tparser.add_argument('-o', '--output_dir', default=input_dir, nargs='*', help=hpstr)\n",
    "\n",
    "\thpstr = \"set whether store data\"\n",
    "\tparser.add_argument('--set_store', default = True, action='store_true', help=hpstr) # add default\n",
    "\n",
    "\targs = parser.parse_args()\n",
    "\treturn(args)\n",
    "\t\t   \n",
    "def print_top(dataset_dir, window_size, parallel, convert, segment, begin_subject, end_subject, output_dir, set_store):\n",
    "\tprint(\"######################## PhysioBank EEG data preprocess ########################\t\\\n",
    "\t\t   \\n#### Author: Dalin Zhang\tUNSW, Sydney\temail: zhangdalin90@gmail.com #####\t\\\n",
    "\t\t   \\n# input directory:\t%s \\\n",
    "\t\t   \\n# window size:\t\t%d \t\\\n",
    "\t\t   \\n# parallel:\t%s \t\\\n",
    "\t\t   \\n# convert:\t\t%s \t\\\n",
    "\t\t   \\n# segment:\t\t%s \t\\\n",
    "\t\t   \\n# begin subject:\t%d \t\\\n",
    "\t\t   \\n# end subject:\t\t%d \t\\\n",
    "\t\t   \\n# output directory:\t%s\t\\\n",
    "\t\t   \\n# set store:\t\t%s \t\\\n",
    "\t\t   \\n##############################################################################\"% \\\n",
    "\t\t\t(dataset_dir,\t\\\n",
    "\t\t\twindow_size,\t\\\n",
    "\t\t\tparallel,       \\\n",
    "\t\t\tconvert,\t\t\\\n",
    "\t\t\tsegment,\t\t\\\n",
    "\t\t\tbegin_subject,\t\\\n",
    "\t\t\tend_subject,\t\\\n",
    "\t\t\toutput_dir,\t\t\\\n",
    "\t\t\tset_store))\n",
    "\treturn None\n",
    "\n",
    "\n",
    "def read_data(file_name):\n",
    "\tf = pyedflib.EdfReader(file_name)\n",
    "\tn = f.signals_in_file\n",
    "\tsignal_labels = f.getSignalLabels()\n",
    "\tsigbufs = np.zeros((n, f.getNSamples()[0]))\n",
    "\tfor i in np.arange(n):\n",
    "\t    sigbufs[i, :] = f.readSignal(i)\n",
    "\tsigbuf_transpose = np.transpose(sigbufs)\n",
    "\tsignal = np.asarray(sigbuf_transpose)\n",
    "\tsignal_labels = np.asarray(signal_labels)\n",
    "\tf._close()\n",
    "\tdel f\n",
    "\treturn signal, signal_labels\n",
    "\n",
    "def data_1Dto2D(data, Y=10, X=11): # comment out by TZ\n",
    "\tdata_2D = np.zeros([Y, X])\n",
    "\tdata_2D[0] = ( \t   \t 0, \t   0,  \t   \t 0, \t   0, data[21], data[22], data[23], \t   0,  \t     0, \t   0, \t \t 0) \n",
    "\tdata_2D[1] = (\t  \t 0, \t   0,  \t   \t 0, data[24], data[25], data[26], data[27], data[28], \t   \t 0,   \t   0, \t \t 0) \n",
    "\tdata_2D[2] = (\t  \t 0, data[29], data[30], data[31], data[32], data[33], data[34], data[35], data[36], data[37], \t \t 0) \n",
    "\tdata_2D[3] = (\t  \t 0, data[38],  data[0],  data[1],  data[2],  data[3],  data[4],  data[5],  data[6], data[39], \t\t 0) \n",
    "\tdata_2D[4] = (data[42], data[40],  data[7],  data[8],  data[9], data[10], data[11], data[12], data[13], data[41], data[43]) \n",
    "\tdata_2D[5] = (\t  \t 0, data[44], data[14], data[15], data[16], data[17], data[18], data[19], data[20], data[45], \t\t 0) \n",
    "\tdata_2D[6] = (\t  \t 0, data[46], data[47], data[48], data[49], data[50], data[51], data[52], data[53], data[54], \t\t 0) \n",
    "\tdata_2D[7] = (\t  \t 0, \t   0, \t \t 0, data[55], data[56], data[57], data[58], data[59], \t   \t 0, \t   0, \t\t 0) \n",
    "\tdata_2D[8] = (\t  \t 0, \t   0, \t \t 0, \t   0, data[60], data[61], data[62], \t   0, \t   \t 0, \t   0, \t\t 0) \n",
    "\tdata_2D[9] = (\t  \t 0, \t   0, \t \t 0, \t   0, \t     0, data[63], \t\t 0, \t   0, \t   \t 0, \t   0, \t\t 0) \n",
    "\treturn data_2D\n",
    "\n",
    "# def data_1Dto2D(data, Y=10, X=11): # add by TZ for huang's proj\n",
    "# \tdata_2D = np.zeros([Y, X])\n",
    "# \tdata_2D[0] = ( \t   \t 0, \t   0,  \t   \t 0, \t   0, \t     0, \t   0, \t     0, \t   0,  \t     0, \t   0, \t \t 0) \n",
    "# \tdata_2D[1] = (\t  \t 0, \t   0,  \t   \t 0, \t   0, \t     0, \t   0, \t     0, \t   0, \t   \t 0,   \t   0, \t \t 0) \n",
    "# \tdata_2D[2] = (\t  \t 0, \t   0,  data[1],  data[2],  data[3],  data[4],  data[5],  data[6],  data[7],   \t   0, \t \t 0) \n",
    "# \tdata_2D[3] = (\t  \t 0,   \t   0,  data[8],  data[9], data[10], data[11], data[12], data[13], data[14],   \t   0, \t\t 0) \n",
    "# \tdata_2D[4] = (   \t 0,   \t   0, data[15], data[16], data[17], data[18], data[19], data[20], data[21],    \t   0,   \t 0) \n",
    "# \tdata_2D[5] = (\t  \t 0,   \t   0,        0, data[22], data[23], data[24], data[25], data[26],        0,   \t   0, \t\t 0) \n",
    "# \tdata_2D[6] = (\t  \t 0,   \t   0,        0, data[27], data[28], data[29], data[30], data[31],    \t 0,   \t   0, \t\t 0) \n",
    "# \tdata_2D[7] = (\t  \t 0, \t   0, \t \t 0,    \t   0,   \t 0,   \t   0,   \t 0,   \t   0, \t   \t 0, \t   0, \t\t 0) \n",
    "# \tdata_2D[8] = (\t  \t 0, \t   0, \t \t 0, \t   0,        0,   \t   0,   \t 0, \t   0, \t   \t 0, \t   0, \t\t 0) \n",
    "# \tdata_2D[9] = (\t  \t 0, \t   0, \t \t 0, \t   0, \t     0,   \t   0, \t\t 0, \t   0, \t   \t 0, \t   0, \t\t 0) \n",
    "# \treturn data_2D\n",
    "\n",
    "def norm_dataset(dataset_1D):\n",
    "\tnorm_dataset_1D = np.zeros([dataset_1D.shape[0], 64])\n",
    "\tfor i in range(dataset_1D.shape[0]):\n",
    "\t\tnorm_dataset_1D[i] = feature_normalize(dataset_1D[i])\n",
    "\treturn norm_dataset_1D\n",
    "\n",
    "def feature_normalize(data):\n",
    "\tmean = data[data.nonzero()].mean()\n",
    "\tsigma = data[data.nonzero()].std()\n",
    "\tdata_normalized = data\n",
    "\tdata_normalized[data_normalized.nonzero()] = (data_normalized[data_normalized.nonzero()] - mean)/sigma\n",
    "\treturn data_normalized\n",
    "\n",
    "def dataset_1Dto2D(dataset_1D):\n",
    "\tdataset_2D = np.zeros([dataset_1D.shape[0], 10, 11])\n",
    "\tfor i in range(dataset_1D.shape[0]):\n",
    "\t\tdataset_2D[i] = data_1Dto2D(dataset_1D[i])\n",
    "\treturn dataset_2D\n",
    "\n",
    "def norm_dataset_1Dto2D(dataset_1D):\n",
    "\tnorm_dataset_2D = np.zeros([dataset_1D.shape[0], 10, 11])\n",
    "\tfor i in range(dataset_1D.shape[0]):\n",
    "\t\tnorm_dataset_2D[i] = feature_normalize(data_1Dto2D(dataset_1D[i]))\n",
    "\treturn norm_dataset_2D\n",
    "\n",
    "def windows(data, size):\n",
    "\tstart = 0\n",
    "\twhile ((start+size) < data.shape[0]):\n",
    "\t\tyield int(start), int(start + size)\n",
    "\t\tstart += (size/2)\n",
    "\n",
    "def segment_signal_without_transition(data, label, window_size):\n",
    "\tfor (start, end) in windows(data, window_size):\n",
    "\t\tif((len(data[start:end]) == window_size) and (len(set(label[start:end]))==1)):\n",
    "\t\t\tif(start == 0):\n",
    "\t\t\t\tsegments = data[start:end]\n",
    "\t\t\t\t# labels = stats.mode(label[start:end])[0][0]\n",
    "\t\t\t\tlabels = np.array(list(set(label[start:end])))\n",
    "\t\t\telse:\n",
    "\t\t\t\tsegments = np.vstack([segments, data[start:end]])\n",
    "\t\t\t\tlabels = np.append(labels, np.array(list(set(label[start:end]))))\n",
    "\t\t\t\t# labels = np.append(labels, stats.mode(label[start:end])[0][0])\n",
    "\treturn segments, labels\n",
    "\n",
    "def apply_mixup(dataset_dir, parallel, convert, segment, window_size, start=1, end=110):\n",
    "\t# initial empty label arrays\n",
    "\tlabel_inter\t= np.empty([0])\n",
    "\t# initial empty data arrays\n",
    "\tif (parallel == True):\n",
    "\t\tdata_inter_cnn\t= np.empty([0, window_size, 10, 11])\n",
    "\t\tdata_inter_rnn\t= np.empty([0, window_size, 64])\n",
    "\telif ((convert == False) and (segment == False)):\n",
    "\t\tdata_inter\t= np.empty([0, 64])\n",
    "\telif ((convert == False) and (segment == True)): \n",
    "\t\tdata_inter\t= np.empty([0, window_size, 64])\n",
    "\telif ((convert == True) and (segment == False)): \n",
    "\t\tdata_inter\t= np.empty([0, 10, 11])\n",
    "\telif ((convert == True) and (segment == True)): \n",
    "\t\tdata_inter\t= np.empty([0, window_size, 10, 11])\n",
    "\n",
    "\tfor j in range(start, end):\n",
    "\t\tif (j == 89):\n",
    "\t\t\tj = 109\n",
    "\t\t# get directory name for one subject\n",
    "\t\tdata_dir = dataset_dir+\"S\"+format(j, '03d')\n",
    "\t\t# get task list for one subject\n",
    "\t\ttask_list = [task for task in os.listdir(data_dir) if os.path.isdir(os.path.join(data_dir, task))]\n",
    "\t\tfor task in task_list:\n",
    "\t\t\tif((\"R02\" in task) or (\"R04\" in task) or (\"R06\" in task)): # R02: eye closed; R04, R06: motor imagery tasks\n",
    "\t\t\t\tprint(task+\" begin:\")\n",
    "\t\t\t\t# get data file name and label file name\n",
    "\t\t\t\tdata_file \t= data_dir+\"/\"+task+\"/\"+task+\".csv\"\n",
    "\t\t\t\tlabel_file \t= data_dir+\"/\"+task+\"/\"+task+\".label.csv\"\n",
    "\t\t\t\t# read data and label\n",
    "\t\t\t\tdata\t\t= pd.read_csv(data_file)\n",
    "\t\t\t\tlabel\t\t= pd.read_csv(label_file)\n",
    "\n",
    "\t\t\t\t\n",
    "\t\t\t\t\n",
    "\t\t\t\t# remove rest label and data during motor imagery tasks\n",
    "\t\t\t\tdata_label\t= pd.concat([data, label], axis=1)\n",
    "\t\t\t\tdata_label\t= data_label.loc[data_label['labels']!= 'rest']\n",
    "\t\t\t\t# get new label\n",
    "\t\t\t\tlabel\t\t= data_label['labels']\n",
    "\t\t\t\t# get new data and normalize\n",
    "\t\t\t\tdata_label.drop('labels', axis=1, inplace=True)\n",
    "\t\t\t\t# data\t\t= data_label.as_matrix() # commented by TZ\n",
    "\t\t\t\tdata = data_label.to_numpy()  # Change from as_matrix() to to_numpy()\n",
    "\t\t\t\t# print(data.shape)\n",
    "\t\t\t\tdata\t\t= norm_dataset(data)\n",
    "\t\t\t\tprint(data.shape)\n",
    "\t\t\t\tprint(label.shape)\n",
    "\t\t\t\tif (parallel == True):\n",
    "\t\t\t\t\t# segment data\n",
    "\t\t\t\t\tdata, label\t= segment_signal_without_transition(data, label, window_size)\n",
    "\t\t\t\t\t# cnn data process\n",
    "\t\t\t\t\tdata_cnn\t= dataset_1Dto2D(data)\n",
    "\t\t\t\t\tdata_cnn\t= data_cnn.reshape(int(data_cnn.shape[0]/window_size), window_size, 10, 11)\n",
    "\t\t\t\t\t# rnn data process\n",
    "\t\t\t\t\tdata_rnn\t= data_cnn.reshape(int(data.shape[0]/window_size), window_size, 64)\n",
    "\t\t\t\telif ((convert == False) and (segment == False)):\n",
    "\t\t\t\t\tpass\n",
    "\t\t\t\telif ((convert == False) and (segment == True)):\n",
    "\t\t\t\t\t# segment data with sliding window \n",
    "\t\t\t\t\tdata, label\t= segment_signal_without_transition(data, label, window_size)\n",
    "\t\t\t\t\tdata\t\t= data.reshape(int(data.shape[0]/window_size), window_size, 64)\n",
    "\t\t\t\telif ((convert == True) and (segment == False)): \n",
    "\t\t\t\t\t# convert 1D data to 2D\n",
    "\t\t\t\t\tdata\t\t= dataset_1Dto2D(data)\n",
    "\t\t\t\telif ((convert == True) and (segment == True)): \n",
    "\t\t\t\t\t# convert 1D data to 2D\n",
    "\t\t\t\t\tdata\t\t= dataset_1Dto2D(data)\n",
    "\t\t\t\t\t# segment data with sliding window \n",
    "\t\t\t\t\tdata, label\t= segment_signal_without_transition(data, label, window_size)\n",
    "\t\t\t\t\tdata\t\t= data.reshape(int(data.shape[0]/window_size), window_size, 10, 11)\n",
    "\t\t\t\t# append new data and label\n",
    "\t\t\t\tif (parallel == True):\n",
    "\t\t\t\t\tdata_inter_cnn\t= np.vstack([data_inter_cnn, data_cnn])\n",
    "\t\t\t\t\tdata_inter_rnn\t= np.vstack([data_inter_rnn, data_rnn])\n",
    "\t\t\t\t\tlabel_inter\t= np.append(label_inter, label)\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tdata_inter\t= np.vstack([data_inter, data])\n",
    "\t\t\t\t\tlabel_inter\t= np.append(label_inter, label)\n",
    "\t\t\telse:\n",
    "\t\t\t\tpass\n",
    "\t# shuffle data\n",
    "\tindex = np.array(range(0, len(label_inter)))\n",
    "\tnp.random.shuffle(index)\n",
    "\tif (parallel==True):\n",
    "\t\tshuffled_data_cnn\t= data_inter_cnn[index]\n",
    "\t\tshuffled_data_rnn\t= data_inter_rnn[index]\n",
    "\t\tshuffled_label \t= label_inter[index]\n",
    "\telse:\n",
    "\t\tshuffled_data\t= data_inter[index]\n",
    "\t\tshuffled_label \t= label_inter[index]\n",
    "\treturn shuffled_data, shuffled_label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######################## PhysioBank EEG data preprocess ########################\t\t\t   \n",
      "#### Author: Dalin Zhang\tUNSW, Sydney\temail: zhangdalin90@gmail.com #####\t\t\t   \n",
      "# input directory:\t../../raw_data_CRNN/ \t\t   \n",
      "# window size:\t\t10 \t\t\t   \n",
      "# parallel:\tFalse \t\t\t   \n",
      "# convert:\t\tTrue \t\t\t   \n",
      "# segment:\t\tTrue \t\t\t   \n",
      "# begin subject:\t1 \t\t\t   \n",
      "# end subject:\t\t108 \t\t\t   \n",
      "# output directory:\t../../pre_processed_dataset/\t\t\t   \n",
      "# set store:\t\tTrue \t\t\t   \n",
      "##############################################################################\n",
      "S001R02 begin:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tianyi Zheng\\AppData\\Local\\Temp\\ipykernel_39068\\3807946645.py:119: RuntimeWarning: Mean of empty slice.\n",
      "  mean = data[data.nonzero()].mean()\n",
      "c:\\ProgramData\\anaconda3\\envs\\tensorflow\\Lib\\site-packages\\numpy\\core\\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "c:\\ProgramData\\anaconda3\\envs\\tensorflow\\Lib\\site-packages\\numpy\\core\\_methods.py:206: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "c:\\ProgramData\\anaconda3\\envs\\tensorflow\\Lib\\site-packages\\numpy\\core\\_methods.py:163: RuntimeWarning: invalid value encountered in divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean,\n",
      "c:\\ProgramData\\anaconda3\\envs\\tensorflow\\Lib\\site-packages\\numpy\\core\\_methods.py:198: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9760, 64)\n",
      "(9760,)\n",
      "S001R04 begin:\n",
      "(9920, 64)\n",
      "(9920,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tianyi Zheng\\AppData\\Local\\Temp\\ipykernel_39068\\3807946645.py:119: RuntimeWarning: Mean of empty slice.\n",
      "  mean = data[data.nonzero()].mean()\n",
      "c:\\ProgramData\\anaconda3\\envs\\tensorflow\\Lib\\site-packages\\numpy\\core\\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "c:\\ProgramData\\anaconda3\\envs\\tensorflow\\Lib\\site-packages\\numpy\\core\\_methods.py:206: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "c:\\ProgramData\\anaconda3\\envs\\tensorflow\\Lib\\site-packages\\numpy\\core\\_methods.py:163: RuntimeWarning: invalid value encountered in divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean,\n",
      "c:\\ProgramData\\anaconda3\\envs\\tensorflow\\Lib\\site-packages\\numpy\\core\\_methods.py:198: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 23\u001b[0m\n\u001b[0;32m     20\u001b[0m print_top(dataset_dir, window_size, parallel, convert, segment, begin_subject, end_subject, output_dir, set_store)\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# print('stop here')\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# exit()\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m shuffled_data, shuffled_label \u001b[38;5;241m=\u001b[39m \u001b[43mapply_mixup\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msegment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwindow_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbegin_subject\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_subject\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# 17m 30s on macbook\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# 21m 5s on WIN desktop\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[5], line 223\u001b[0m, in \u001b[0;36mapply_mixup\u001b[1;34m(dataset_dir, parallel, convert, segment, window_size, start, end)\u001b[0m\n\u001b[0;32m    220\u001b[0m \tdata\t\t\u001b[38;5;241m=\u001b[39m dataset_1Dto2D(data)\n\u001b[0;32m    221\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m ((convert \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m (segment \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)): \n\u001b[0;32m    222\u001b[0m \t\u001b[38;5;66;03m# convert 1D data to 2D\u001b[39;00m\n\u001b[1;32m--> 223\u001b[0m \tdata\t\t\u001b[38;5;241m=\u001b[39m \u001b[43mdataset_1Dto2D\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    224\u001b[0m \t\u001b[38;5;66;03m# segment data with sliding window \u001b[39;00m\n\u001b[0;32m    225\u001b[0m \tdata, label\t\u001b[38;5;241m=\u001b[39m segment_signal_without_transition(data, label, window_size)\n",
      "Cell \u001b[1;32mIn[5], line 128\u001b[0m, in \u001b[0;36mdataset_1Dto2D\u001b[1;34m(dataset_1D)\u001b[0m\n\u001b[0;32m    126\u001b[0m dataset_2D \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros([dataset_1D\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m11\u001b[39m])\n\u001b[0;32m    127\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(dataset_1D\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]):\n\u001b[1;32m--> 128\u001b[0m \tdataset_2D[i] \u001b[38;5;241m=\u001b[39m data_1Dto2D(dataset_1D[i])\n\u001b[0;32m    129\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dataset_2D\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# input directory:      ../raw_data/               \n",
    "# window size:          10                         \n",
    "# parallel:     False                      \n",
    "# convert:              True                       \n",
    "# segment:              True                       \n",
    "# begin subject:        1                          \n",
    "# end subject:          108                        \n",
    "# output directory:     ../raw_data/                       \n",
    "# set store:            True  \n",
    "\n",
    "dataset_dir\t\t=\t\"../../raw_data_CRNN/\" # get_args().directory\n",
    "window_size\t\t=\t10 # get_args().window\n",
    "parallel\t\t=\tFalse # get_args().parallel\n",
    "convert\t\t\t=\tTrue # get_args().convert\n",
    "segment\t\t\t=\tTrue # get_args().segment\n",
    "begin_subject\t=\t1 # get_args().begin\n",
    "end_subject\t\t=\t108 # get_args().end\n",
    "output_dir\t\t=\t\"../../pre_processed_dataset/\" # get_args().output_dir\n",
    "set_store\t\t=\tTrue # get_args().set_store\n",
    "print_top(dataset_dir, window_size, parallel, convert, segment, begin_subject, end_subject, output_dir, set_store)\n",
    "# print('stop here')\n",
    "# exit()\n",
    "shuffled_data, shuffled_label = apply_mixup(dataset_dir, parallel, convert, segment, window_size, begin_subject, end_subject+1)\n",
    "# 17m 30s on macbook\n",
    "# 21m 5s on WIN desktop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WE ARE HERE!!!\n"
     ]
    }
   ],
   "source": [
    "if (set_store == True):\n",
    "\tif (parallel == True):\n",
    "\t\toutput_data_cnn = output_dir+\"parallel_cnn_rnn/raw_data/\"+str(begin_subject)+\"_\"+str(end_subject)+\"_shuffle_cnn_dataset.pkl\"\n",
    "\t\toutput_data_rnn = output_dir+\"parallel_cnn_rnn/raw_data/\"+str(begin_subject)+\"_\"+str(end_subject)+\"_shuffle_rnn_dataset.pkl\"\n",
    "\t\toutput_label= output_dir+\"parallel_cnn_rnn/raw_data/\"+str(begin_subject)+\"_\"+str(end_subject)+\"_shuffle_labels.pkl\"\n",
    "\telif ((convert == False) and (segment == False)): # default to here\n",
    "\t\toutput_data = output_dir+\"1D_CNN/raw_data/\"+str(begin_subject)+\"_\"+str(end_subject)+\"_shuffle_dataset_1D.pkl\"\n",
    "\t\toutput_label= output_dir+\"1D_CNN/raw_data/\"+str(begin_subject)+\"_\"+str(end_subject)+\"_shuffle_labels_1D.pkl\"\n",
    "\telif ((convert == False) and (segment == True)): \n",
    "\t\toutput_data = output_dir+\"1D_CNN/raw_data/window_1D/\"+str(begin_subject)+\"_\"+str(end_subject)+\"_shuffle_dataset_1D_win_\"+str(window_size)+\".pkl\"\n",
    "\t\toutput_label= output_dir+\"1D_CNN/raw_data/window_1D/\"+str(begin_subject)+\"_\"+str(end_subject)+\"_shuffle_labels_1D_win_\"+str(window_size)+\".pkl\"\n",
    "\telif ((convert == True) and (segment == False)): \n",
    "\t\toutput_data = output_dir+\"2D_CNN/raw_data/\"+str(begin_subject)+\"_\"+str(end_subject)+\"_shuffle_dataset_2D.pkl\"\n",
    "\t\toutput_label= output_dir+\"2D_CNN/raw_data/\"+str(begin_subject)+\"_\"+str(end_subject)+\"_shuffle_labels_2D.pkl\"\n",
    "\telif ((convert == True) and (segment == True)): # cascade\n",
    "\t\tprint(\"WE ARE HERE!!!\")\n",
    "\t\toutput_data = output_dir+\"3D_CNN/raw_data/\"+str(begin_subject)+\"_\"+str(end_subject)+\"_shuffle_dataset_3D_win_\"+str(window_size)+\".pkl\"\n",
    "\t\toutput_label= output_dir+\"3D_CNN/raw_data/\"+str(begin_subject)+\"_\"+str(end_subject)+\"_shuffle_labels_3D_win_\"+str(window_size)+\".pkl\"\n",
    "\n",
    "\tos.makedirs(os.path.dirname(output_data), exist_ok=True) # add by TZ\n",
    "\n",
    "\tif (parallel ==True):\n",
    "\t\twith open(output_data_cnn, \"wb\") as fp:\n",
    "\t\t\tpickle.dump(shuffled_data_cnn, fp, protocol=4) \n",
    "\t\twith open(output_data_rnn, \"wb\") as fp:\n",
    "\t\t\tpickle.dump(shuffled_data_rnn, fp, protocol=4) \n",
    "\t\twith open(output_label, \"wb\") as fp:\n",
    "\t\t\tpickle.dump(shuffled_label, fp)\n",
    "\telse: # default to here\n",
    "\t\twith open(output_data, \"wb\") as fp:\n",
    "\t\t\tpickle.dump(shuffled_data, fp, protocol=4)\n",
    "\t\twith open(output_label, \"wb\") as fp:\n",
    "\t\t\tpickle.dump(shuffled_label, fp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
